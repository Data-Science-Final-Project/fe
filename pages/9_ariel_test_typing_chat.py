#  imports 
import os, sys, json, uuid, asyncio, re
from datetime import datetime

import streamlit as st
import torch, fitz, docx, numpy as np
from bidi.algorithm import get_display       
from openai import AsyncOpenAI, OpenAI
from dotenv import load_dotenv
from streamlit_js import st_js, st_js_blocking

from app_resources import mongo_client, pinecone_client, model

#  ENV & GLOBALS 
load_dotenv()
DATABASE_NAME  = os.getenv("DATABASE_NAME")
OPENAI_API_KEY = os.getenv("OPEN_AI")

client_async_openai = AsyncOpenAI(api_key=OPENAI_API_KEY)
client_sync_openai  = OpenAI(api_key=OPENAI_API_KEY)

torch.classes.__path__ = []        # Streamlit-Torch bug-workaround
os.environ["TOKENIZERS_PARALLELISM"] = "false"

judgment_index = pinecone_client.Index("judgments-names")
law_index      = pinecone_client.Index("laws-names")

db = mongo_client[DATABASE_NAME]
judgment_collection = db["judgments"]
law_collection      = db["laws"]
conversation_coll   = db["conversations"]

#  UI CSS 
st.set_page_config(page_title="Ask Mini Lawyer", page_icon="锔", layout="wide")
st.markdown("""
<style>
.chat-container{background:#1E1E1E;padding:20px;border-radius:10px}
.chat-header{color:#4CAF50;font-size:36px;font-weight:bold;text-align:center}
.user-message{background:#4CAF50;color:#ecf2f8;padding:10px;border-radius:10px;margin:10px}
.bot-message{background:#44475a;color:#ecf2f8;padding:10px;border-radius:10px;margin:10px}
.timestamp{font-size:0.75em;color:#bbb}
.law-card{border:1px solid #e0e0e0;border-radius:10px;padding:20px;margin-bottom:15px;
          box-shadow:0 2px 4px rgba(0,0,0,0.1);background:#f9f9f9}
.law-title{font-size:20px;font-weight:bold;color:#333}
.law-description{font-size:16px;color:#444;margin:10px 0}
.law-meta{font-size:14px;color:#555}
.stButton>button{background:#7ce38b;color:#fff;font-size:14px;border:none;padding:8px 16px;border-radius:5px;cursor:pointer}
.stButton>button:hover{background:#69d67a}
</style>
""", unsafe_allow_html=True)

app_mode = st.sidebar.selectbox("Choose module", ["Chat Assistant", "Legal Finder"])

#  GENERAL HELPERS 
ls_get = lambda k: st_js_blocking(f"return localStorage.getItem('{k}');", key="ls_"+k)
ls_set = lambda k,v: st_js(f"localStorage.setItem('{k}', '{v}');")

# ---------- RTL normalization ----------
heb  = re.compile(r'[-转]')
SALUT= r'\b(|专|专\.?|\'?|专转|"专|"专\.?)\b'
def rtl_norm(t:str)->str:
    if not heb.search(t): return t
    try: t = get_display(t)
    except Exception: t = " ".join(w[::-1] if heb.search(w) else w for w in t.split())
    t = re.sub(SALUT, '', t)
    return re.sub(r'\s{2,}', ' ', t).strip()

read_pdf  = lambda f: "".join(rtl_norm(p.get_text()) for p in fitz.open(stream=f.read(), filetype="pdf"))
read_docx = lambda f: "\n".join(rtl_norm(p.text)     for p in docx.Document(f).paragraphs if p.text.strip())

def add_msg(role, txt):
    st.session_state.setdefault("messages", []).append(
        {"role": role, "content": txt, "timestamp": datetime.now().strftime("%H:%M:%S")})

def show_msgs():
    for m in st.session_state.get("messages", []):
        css = "user-message" if m["role"]=="user" else "bot-message"
        st.markdown(f"<div class='{css}'>{m['content']}<div class='timestamp'>{m['timestamp']}</div></div>", unsafe_allow_html=True)

def chunk_text(txt, L=450):
    sent=re.split(r'(?:\.|\?|!)\s+', txt); out,cur=[], ""
    for s in sent:
        if len(cur)+len(s)>L and cur: out.append(cur.strip()); cur=s
        else: cur+=" "+s
    if cur.strip(): out.append(cur.strip())
    return out[:20]

contains_english=lambda t: bool(re.search(r'[A-Za-z]', t))
def ensure_hebrew(t):
    if sum(contains_english(w) for w in t.split())<=3: return t
    r=client_sync_openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role":"user","content":"转专 转 拽住  注专转    转:\n"+t}],
        temperature=0,max_tokens=len(t)//2)
    return r.choices[0].message.content.strip()

#  CLASSIFICATION 
CATEGORIES = {
 "转_驻专":{"regex":[r"驻专(?:|)", r"住\s+?注住拽", r"termination\s+notice"]},
 "_注":  {"regex":[r"住\s+注|employment agreement"]},
 "NDA":          {"regex":[r"住转|confidentiality"]},
 "CEASE_DESIST": {"regex":[r"|驻住拽|cease and desist"]},
 "转拽":        {"regex":[r"转拽|by.?law|policy"]},
 "转_转注":    {"regex":[r"转\s+转注|转注|转注"]},
 "驻住拽_":      {"regex":[r"驻住拽[-\s]?|转.?砖驻"]},
 "转_专":     {"regex":[]}
}
CLS_SYSTEM = "转 住 住 砖驻. 专 转转 转 : "+", ".join(CATEGORIES)

def classify_doc(txt:str)->str:
    for lab,d in CATEGORIES.items():
        if any(re.search(p,txt,re.I) for p in d["regex"]): return lab
    try:
        resp=client_sync_openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role":"system","content":CLS_SYSTEM},
                      {"role":"user","content":txt[:1500]}],
            temperature=0,max_tokens=10)
        lab=resp.choices[0].message.content.strip()
    except: lab="转_专"
    return lab if lab in CATEGORIES else "转_专"

#  TEMPLATES 
H = lambda s: s+"  **注 注专转    转. 爪 拽专 住驻专 (拽  驻住状) 专  拽注.**"
PROMPTS={
 "转_驻专":dict(summary=H("住 转 驻专: 1. 驻专 注 转专, 2. 转 转砖, 3. 爪注 爪."),
                      answer =H("转 注\" -注. 砖 专拽 注 住 转 拽 注 专.")),
 "_注":  dict(summary=H("住  注: 1. 转 注住拽, 2. 住注驻 住转 -转专转, 3. 住 爪转."),
                      answer =H("转 注\" -注. 转 转 住注驻 .")),
 "NDA":          dict(summary=H("住 NDA: 1. 专转 注 住, 2. 转拽驻转 住, 3. 爪注 驻."),
                      answer =H("转 注\" 拽-专.")),
 "CEASE_DESIST": dict(summary=H("住 转 专: 1. 注转, 2. 专砖转, 3. 转  驻."),
                      answer =H("转 注\" 爪.")),
 "转拽":        dict(summary=H("住 转拽/转: 1. 专转, 2. 转/转, 3. 住 -爪转."),
                      answer =H("转 注\" 专转.")),
 "转_转注":    dict(summary=H("住 转 转注: 1. 注转, 2. 住注, 3.   ."),
                      answer =H("转 注\" 爪.")),
 "驻住拽_":      dict(summary=H("住 驻住拽-: 1. 砖 砖驻转, 2. 拽注转, 3. ."),
                      answer =H("转 注\".")),
 "_":            dict(summary=H("住 转 住: 转拽爪专, 拽转 注拽专转, 砖转."),
                      answer =H("转 注\"."))
}
tmpl=lambda l,k: PROMPTS.get(l,PROMPTS["_"])[k]

#  RETRIEVAL (RAG) 
embed=lambda t: model.encode([t],normalize_embeddings=True)[0]

async def retrieve(query,doc):
    q_emb=embed(query); secs=[embed(c) for c in chunk_text(doc)] if doc else []
    cand={"law":{}, "judg":{}}

    async def add(m,kind):
        meta,score=m.get("metadata",{}), m.get("score",0)
        key="IsraelLawID" if kind=="law" else "CaseNumber"; _id=meta.get(key)
        if not _id: return
        coll=law_collection if kind=="law" else judgment_collection
        d=coll.find_one({key:_id}); 
        if d: cand[kind].setdefault(_id,{"doc":d,"scores":[]})["scores"].append(score)

    async def scan(e):
        rl,rj=await asyncio.gather(
            asyncio.to_thread(law_index.query,vector=e.tolist(),top_k=1,include_metadata=True),
            asyncio.to_thread(judgment_index.query,vector=e.tolist(),top_k=1,include_metadata=True))
        [await add(m,"law") for m in rl.get("matches",[])]
        [await add(m,"judg")for m in rj.get("matches",[])]

    await asyncio.gather(*(scan(e) for e in secs))
    for m in law_index.query(vector=q_emb.tolist(),top_k=3,include_metadata=True).get("matches",[]):  await add(m,"law")
    for m in judgment_index.query(vector=q_emb.tolist(),top_k=3,include_metadata=True).get("matches",[]): await add(m,"judg")

    top=lambda d: sorted(d.values(), key=lambda x:-np.mean(x["scores"]))[:3]
    return [x["doc"] for x in top(cand["law"])],[x["doc"] for x in top(cand["judg"])]

#  SELF-CHECK 
async def citations_ok(ans:str)->bool:
    if contains_english(ans): return False
    try:
        r=await client_async_openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role":"user","content":"Does every claim have an explicit citation? Answer Yes/No.\n"+ans}],
            temperature=0,max_tokens=3)
        return "yes" in r.choices[0].message.content.lower()
    except: return True

#  CHAT ASSISTANT 
def chat_assistant():
    st.markdown('<div class="chat-header"> Ask Mini Lawyer</div>',unsafe_allow_html=True)
    if "cid" not in st.session_state:
        cid=ls_get("AMLChatId") or str(uuid.uuid4()); ls_set("AMLChatId",cid); st.session_state.cid=cid
    if "messages" not in st.session_state:
        conv=conversation_coll.find_one({"local_storage_id":st.session_state.cid})
        st.session_state["messages"]=conv.get("messages",[]) if conv else []
    st.session_state.setdefault("name",None)

    if not st.session_state["name"]:
        with st.form("name"):
            n=st.text_input("住 砖 转转 砖:")
            if st.form_submit_button("转") and n:
                st.session_state["name"]=n
                add_msg("assistant",f"砖 {n},  驻砖专 注专?")
                conversation_coll.update_one({"local_storage_id":st.session_state.cid},
                                             {"$set":{"user_name":n,"messages":st.session_state["messages"]}},upsert=True)
                st.rerun()
        return

    st.markdown('<div class="chat-container">',unsafe_allow_html=True); show_msgs(); st.markdown("</div>",unsafe_allow_html=True)

    # upload
    up=st.file_uploader(" 注 住",type=["pdf","docx"])
    if up:
        raw_txt = read_pdf(up) if up.type=="application/pdf" else read_docx(up)
        st.session_state.doctype = classify_doc(raw_txt)
        st.session_state.doc     = "\n".join(l for l in raw_txt.splitlines() if heb.search(l))
        st.success(f"住 住: {st.session_state.doctype}")

    # summary
    if hasattr(st.session_state,"doc") and st.button(" 住"):
        with st.spinner("住..."):
            prompt=tmpl(st.session_state.doctype,"summary")+"\n"+st.session_state.doc
            r=asyncio.run(client_async_openai.chat.completions.create(
                model="gpt-4o-mini",messages=[{"role":"user","content":prompt}],
                temperature=0,max_tokens=700))
            st.session_state.summary = ensure_hebrew(r.choices[0].message.content.strip())
    if st.session_state.get("summary"):
        st.markdown("### 住:")
        st.markdown(f"<div dir='rtl' style='text-align:right;line-height:1.6'>{st.session_state.summary}</div>",unsafe_allow_html=True)

    # answer generator
    async def generate_answer(q):
        laws,judg = await retrieve(q,st.session_state.get("doc",""))
        law_txt = "\n\n".join(d.get("Description","")[:800] for d in laws) or " 爪 拽 专."
        jud_txt = "\n\n".join(d.get("Description","")[:800] for d in judg) or " 爪 驻住拽  专."
        sys = tmpl(st.session_state.get("doctype","_"),"answer")+\
              f"\n\n--- 住 ---\n{st.session_state.get('doc','')[:1500]}" +\
              f"\n\n--- 拽 ---\n{law_txt}" +\
              f"\n\n--- 驻住拽  ---\n{jud_txt}"
        r=await client_async_openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":sys},{"role":"user","content":q}],
            temperature=0,max_tokens=700)
        return r.choices[0].message.content.strip()

    async def handle(q):
        ans=ensure_hebrew(await generate_answer(q))
        if await citations_ok(ans): return ans
        # 住 砖 专
        harder=" 爪 拽专 住驻专 (拽/驻住状) 专  砖驻."
        ans2=ensure_hebrew(await generate_answer(q+"\n"+harder))
        return ans2

    with st.form("ask",clear_on_submit=True):
        q=st.text_area("拽 砖 砖驻转:",height=100)
        if st.form_submit_button("砖") and q.strip():
            ans=asyncio.run(handle(q.strip()))
            add_msg("user",q.strip()); add_msg("assistant",ans)
            conversation_coll.update_one({"local_storage_id":st.session_state.cid},
                                         {"$set":{"messages":st.session_state["messages"],
                                                  "user_name":st.session_state["name"]}},upsert=True)
            st.rerun()

    if st.button(" 拽"):
        conversation_coll.delete_one({"local_storage_id":st.session_state.cid})
        st_js("localStorage.clear()"); st.session_state.clear(); st.rerun()

#  LEGAL FINDER 
def legal_finder():
    st.title("Legal Finder")
    kind=st.selectbox("Search for",["Judgment","Law"])
    scen=st.text_area("Scenario")
    if st.button("Find") and scen:
        emb=embed(scen)
        idx=judgment_index if kind=="Judgment" else law_index
        key="CaseNumber" if kind=="Judgment" else "IsraelLawID"
        res=idx.query(vector=emb.tolist(),top_k=5,include_metadata=True)
        for m in res.get("matches",[]):
            _id=m.get("metadata",{}).get(key)
            coll=judgment_collection if kind=="Judgment" else law_collection
            doc=coll.find_one({key:_id})
            if doc:
                st.markdown(f"""<div class='law-card'><div class='law-title'>{doc.get('Name','')} (ID:{_id})</div>
                                <div class='law-description'>{doc.get('Description','')[:600]}...</div></div>""",unsafe_allow_html=True)

#  MAIN 
if app_mode=="Chat Assistant":
    chat_assistant()
else:
    legal_finder()
